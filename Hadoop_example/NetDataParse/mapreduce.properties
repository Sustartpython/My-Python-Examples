
#hadoop
fs.defaultFS=hdfs://localcluster
hadoop.hostname1=Hadoop2x-04
hadoop.hostname2=Hadoop2x-05
hadoop.hostname3=Hadoop2x-06
dfs.nameservices=localcluster
dfs.ha.namenodes.localcluster=nn1,nn2
dfs.client.failover.proxy.provider.localcluster=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
dfs.namenode.rpc-address.localcluster.nn1=${hadoop.hostname1}:9000
dfs.namenode.rpc-address.localcluster.nn2=${hadoop.hostname2}:9000
dfs.client.read.shortcircuit=true
dfs.domain.socket.path=/usr/local/vipcloud/data/data1/dn._PORT
dfs.blocksize=268435456
dfs.replication=3
#yarn and mapreduce
mapreduce.app-submission.cross-platform=true
mapreduce.framework.name=yarn
yarn.resourcemanager.ha.enabled=true
yarn.resourcemanager.ha.rm-ids=rm1,rm2
yarn.app.mapreduce.am.staging-dir=/yarn/staging
yarn.resourcemanager.address.rm1=${hadoop.hostname1}:8032
yarn.resourcemanager.scheduler.address.rm1=${hadoop.hostname1}:8030
yarn.resourcemanager.address.rm2=${hadoop.hostname2}:8032
yarn.resourcemanager.scheduler.address.rm2=${hadoop.hostname2}:8030
mapreduce.jobhistory.webapp.address=${hadoop.hostname3}:19888
mapreduce.jobhistory.address=${hadoop.hostname3}:10020
spark.yarn.historyServer.address=${hadoop.hostname2}:18080
mapreduce.task.progress-report.interval=3000
mapreduce.reduce.shuffle.input.buffer.percent=0.5
#hbase
hbase.rootdir=hdfs://localcluster/localhbase
zookeeper.znode.parent=/localhbase
hbase.zookeeper.quorum=hadoop2x-04,hadoop2x-05,hadoop2x-06
#zookeeper
zookeeper.hquorum.peer=hadoop2x-04,hadoop2x-05,hadoop2x-06
zookeeper.session.timeout=5000
zookeeper.connection.timeout=20000

#custom
mapreduce.job.queuename=default
mapreduce.map.memory.mb=4096
mapreduce.reduce.memory.mb=4096
mapreduce.map.java.opts=-Xmx4000m
mapreduce.reduce.java.opts=-Xmx4000m -Xms4000m
online.znode.path=/vipcloud/newonlinedata
solr.zk.root=/solr2
solr.node.id=-999
change.node.one.time=10

fs.permissions.umask-mode=002
#mapred.reduce.slowstart.completed.maps=0.85
#mapreduce.job.reduce.slowstart.completedmaps=0.85
